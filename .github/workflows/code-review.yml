name: AI Code Review

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write

jobs:
  code-review:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for accurate diff

      - name: Get diff
        id: diff
        run: |
          # Generate diff between base and head
          git diff origin/${{ github.base_ref }}...HEAD > diff.txt
          
          # Check if diff is not empty
          if [ ! -s diff.txt ]; then
            echo "No changes detected"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Diff size: $(wc -c < diff.txt) bytes"
          fi

      - name: Call Code Review API
        if: steps.diff.outputs.has_changes == 'true'
        id: review
        run: |
          # Create JSON payload
          DIFF_CONTENT=$(cat diff.txt | jq -Rs .)
          
          PAYLOAD=$(jq -n \
            --arg diff "$DIFF_CONTENT" \
            --arg language "python" \
            --arg repo "${{ github.repository }}" \
            --arg commit "${{ github.event.pull_request.head.sha }}" \
            --arg author "${{ github.event.pull_request.user.login }}" \
            --argjson pr_number "${{ github.event.pull_request.number }}" \
            '{
              diff: $diff,
              language: $language,
              context: {
                repo: $repo,
                commit_sha: $commit,
                pr_number: $pr_number,
                author: $author
              }
            }')
          
          # Call API with retry logic
          max_attempts=3
          attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            echo "Attempt $attempt of $max_attempts"
            
            response=$(curl -s -w "\n%{http_code}" -X POST \
              "${{ secrets.REVIEW_API_URL }}/review" \
              -H "Authorization: Bearer ${{ secrets.REVIEW_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD")
            
            http_code=$(echo "$response" | tail -n1)
            body=$(echo "$response" | head -n-1)
            
            if [ "$http_code" = "200" ]; then
              echo "$body" > review.json
              echo "Review completed successfully"
              break
            else
              echo "Request failed with status $http_code"
              echo "$body"
              
              if [ $attempt -lt $max_attempts ]; then
                echo "Retrying in 5 seconds..."
                sleep 5
              else
                echo "Max retry attempts reached"
                exit 1
              fi
            fi
            
            attempt=$((attempt + 1))
          done

      - name: Format review as markdown
        if: steps.diff.outputs.has_changes == 'true'
        id: format
        run: |
          # Extract markdown from review response
          # The API returns a ReviewResponse object, we need to call to_markdown()
          # For now, we'll format it manually from the JSON
          
          python3 <<'EOF'
          import json
          import sys
          
          try:
              with open('review.json', 'r') as f:
                  review = json.load(f)
              
              # Build markdown
              lines = ["## ü§ñ AI Code Review", ""]
              
              summary = review.get('summary', 'Code review completed')
              score = review.get('score', 0)
              findings = review.get('findings', [])
              
              if not findings:
                  lines.append("‚úÖ No issues found! Great work!")
                  lines.append("")
              else:
                  # Group by severity
                  critical = [f for f in findings if f['severity'] == 'critical']
                  high = [f for f in findings if f['severity'] == 'high']
                  medium = [f for f in findings if f['severity'] == 'medium']
                  low = [f for f in findings if f['severity'] == 'low']
                  
                  # Add prominent banner if critical issues found
                  if critical:
                      lines.extend([
                          "> [!WARNING]",
                          "> **‚ö†Ô∏è CRITICAL ISSUES DETECTED**",
                          ">",
                          f"> Found **{len(critical)} critical** issue(s) that require immediate attention.",
                          f"> Please review and address before merging.",
                          ""
                      ])
                  
                  # Add issue counts summary
                  counts = []
                  if critical:
                      counts.append(f"üî¥ {len(critical)} Critical")
                  if high:
                      counts.append(f"üü† {len(high)} High")
                  if medium:
                      counts.append(f"üü° {len(medium)} Medium")
                  if low:
                      counts.append(f"üü¢ {len(low)} Low")
                  
                  lines.append(f"**Issues Found:** {' | '.join(counts)}")
                  lines.append("")
                  
                  def format_findings(findings, emoji, title):
                      if not findings:
                          return []
                      result = [f"### {emoji} {title} ({len(findings)})", ""]
                      for f in findings:
                          location = f"`{f['file']}:{f['line']}`" if f.get('line') else f"`{f['file']}`"
                          result.append(f"- **{f['category'].title()}** in {location}")
                          result.append(f"  > {f['message']}")
                          result.append(f"  > **Suggestion:** {f['suggestion']}")
                          result.append("")
                      return result
                  
                  lines.extend(format_findings(critical, "üî¥", "Critical Issues"))
                  lines.extend(format_findings(high, "üü†", "High Severity"))
                  lines.extend(format_findings(medium, "üü°", "Medium Severity"))
                  lines.extend(format_findings(low, "üü¢", "Low Severity"))
              
              lines.append("")
              lines.append(f"**Summary:** {summary}")
              lines.append(f"**Quality Score:** {score:.1f}/10")
              
              # Footer
              metadata = review.get('metadata', {})
              model = metadata.get('model', 'unknown')
              execution_time = metadata.get('execution_time_ms', 0)
              
              lines.extend([
                  "",
                  "---",
                  f"*Reviewed by AI agents using {model} in {execution_time}ms*"
              ])
              
              markdown = "\\n".join(lines)
              
              # Write to file
              with open('review_comment.md', 'w') as f:
                  f.write(markdown)
              
              print("Review formatted successfully")
              
              # Print summary to workflow logs
              print(f"\nReview Summary:")
              print(f"  Quality Score: {score:.1f}/10")
              print(f"  Total Findings: {len(findings)}")
              if findings:
                  critical_count = len([f for f in findings if f['severity'] == 'critical'])
                  high_count = len([f for f in findings if f['severity'] == 'high'])
                  medium_count = len([f for f in findings if f['severity'] == 'medium'])
                  low_count = len([f for f in findings if f['severity'] == 'low'])
                  print(f"  Critical: {critical_count}")
                  print(f"  High: {high_count}")
                  print(f"  Medium: {medium_count}")
                  print(f"  Low: {low_count}")
                  
                  if critical_count > 0:
                      print(f"\n‚ö†Ô∏è WARNING: {critical_count} critical issue(s) detected!")
              
          except Exception as e:
              print(f"Error formatting review: {e}", file=sys.stderr)
              sys.exit(1)
          EOF

      - name: Post review comment
        if: steps.diff.outputs.has_changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reviewComment = fs.readFileSync('review_comment.md', 'utf8');
            
            // Check if we already posted a review
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('ü§ñ AI Code Review')
            );
            
            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: reviewComment
              });
              console.log('Updated existing review comment');
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: reviewComment
              });
              console.log('Posted new review comment');
            }

      - name: Summary report
        if: steps.diff.outputs.has_changes == 'true'
        run: |
          # Report critical issues as warnings instead of failing the workflow
          CRITICAL_COUNT=$(jq '[.findings[] | select(.severity == "critical")] | length' review.json)
          HIGH_COUNT=$(jq '[.findings[] | select(.severity == "high")] | length' review.json)
          TOTAL_COUNT=$(jq '.findings | length' review.json)
          
          echo "üìä Code Review Summary:"
          echo "  Total Issues: $TOTAL_COUNT"
          echo "  Critical: $CRITICAL_COUNT"
          echo "  High: $HIGH_COUNT"
          
          if [ "$CRITICAL_COUNT" -gt 0 ]; then
            echo "::warning::‚ö†Ô∏è Found $CRITICAL_COUNT critical severity issue(s) - Please review before merging"
          fi
          
          if [ "$TOTAL_COUNT" -eq 0 ]; then
            echo "‚úÖ No issues found - Great work!"
          fi

      - name: No changes detected
        if: steps.diff.outputs.has_changes == 'false'
        run: |
          echo "No changes to review"
