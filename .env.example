# LLM Provider Configuration
# Choose: "openai" or "groq"
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Groq Configuration (optional, alternative to OpenAI)
GROQ_API_KEY=gsk_your-groq-api-key-here
GROQ_MODEL=llama-3.3-70b-versatile

# API Authentication
REVIEW_API_KEY=your-secure-api-key-here

# Rate Limiting
RATE_LIMIT_PER_MINUTE=10

# Ray Serve Configuration
ENABLE_RAY_SERVE=false
RAY_SERVE_HOST=0.0.0.0
RAY_SERVE_PORT=8000
RAY_NUM_REPLICAS=2
RAY_MAX_CONCURRENT_QUERIES=10

# Guardrails Configuration
MAX_FINDINGS_PER_REVIEW=20
MAX_TOKENS_PER_REVIEW=15000
ENABLE_LLM_JUDGE_GUARDRAILS=true

# Application Settings
LOG_LEVEL=INFO
REQUEST_TIMEOUT_SECONDS=120
MAX_DIFF_SIZE_BYTES=1048576

# CORS Settings (comma-separated origins)
CORS_ORIGINS=*

# Debug Mode
DEBUG=false
